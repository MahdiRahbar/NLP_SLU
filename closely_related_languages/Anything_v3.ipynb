{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IH_TlH3wc3a3"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "from keras.models import Model\n",
        "from keras.layers import GRU, Input, Dense, TimeDistributed, Activation, RepeatVector, Bidirectional\n",
        "from keras.layers import Embedding\n",
        "from keras.optimizers import Adam\n",
        "from keras.losses import sparse_categorical_crossentropy\n",
        "from keras.models import Sequential\n",
        "import collections\n",
        "import helper\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras import models, layers\n",
        "from keras import backend\n",
        "import pickle\n",
        "from tensorflow.keras.layers import Bidirectional, Conv1D, MaxPool1D, Dense, Flatten, Dropout, AveragePooling2D, LSTM, TimeDistributed, Attention\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import f1_score,recall_score,precision_score, confusion_matrix\n",
        "from keras_self_attention import SeqSelfAttention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZMX6Xm7Bdek",
        "outputId": "b0bfac96-70fa-431b-f468-8b42241d0ca5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras-self-attention in /usr/local/lib/python3.7/dist-packages (0.51.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-self-attention) (1.21.6)\n"
          ]
        }
      ],
      "source": [
        "pip install keras-self-attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARq3Hlw6c3a7",
        "outputId": "49533f54-102b-4ef9-db01-39488c698bba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/SLU Semesters/SLU 3rd Semester/NLP/Fifth Competition\n",
            "Anything-v3.ipynb  Neural_Machine_Translation.ipynb  \u001b[0m\u001b[01;34mtrain-05\u001b[0m/\n",
            "\u001b[01;34mmodels\u001b[0m/            \u001b[01;34mtest-05\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/SLU Semesters/SLU 3rd Semester/NLP/Fifth Competition/\n",
        "\n",
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xxjx_t4yfV0y"
      },
      "outputs": [],
      "source": [
        "def read_data(file_name):\n",
        "    output = []\n",
        "    cur_sent = []\n",
        "    source_file = open(file_name, 'r', encoding='utf-8')\n",
        "    text = source_file.read()\n",
        "\n",
        "    for current in (text.split('\\n')):\n",
        "        if current == '<s>':\n",
        "            cur_sent = []\n",
        "            continue\n",
        "        if current == '</s>':\n",
        "            output.append(cur_sent)\n",
        "            continue\n",
        "        if current in '()':\n",
        "            continue\n",
        "        else:\n",
        "            cur_sent.append(current.lower())\n",
        "\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9v8T6Dtitl4",
        "outputId": "2d7c7fd1-451a-4d27-bdb0-b2cd732fdac8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Anything-v3.ipynb  Neural_Machine_Translation.ipynb  \u001b[0m\u001b[01;34mtrain-05\u001b[0m/\n",
            "\u001b[01;34mmodels\u001b[0m/            \u001b[01;34mtest-05\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jA4UyvNtc3a8"
      },
      "outputs": [],
      "source": [
        "# source: https://towardsdatascience.com/neural-machine-translation-with-python-c2f0a34f7dd\n",
        "def tokenize(x):\n",
        "    x_tk = Tokenizer(char_level = False)\n",
        "    x_tk.fit_on_texts(x)\n",
        "    return x_tk.texts_to_sequences(x), x_tk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "di7wYtWac3a9"
      },
      "outputs": [],
      "source": [
        "# source: https://towardsdatascience.com/neural-machine-translation-with-python-c2f0a34f7dd\n",
        "def pad(x, length=None):\n",
        "    if length is None:\n",
        "        length = max([len(sentence) for sentence in x])\n",
        "    return pad_sequences(x, maxlen = length, padding = 'post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxVc8XYoc3a9"
      },
      "outputs": [],
      "source": [
        "# source: https://towardsdatascience.com/neural-machine-translation-with-python-c2f0a34f7dd\n",
        "def preprocess(x, y):\n",
        "    preprocess_x, x_tk = tokenize(x)\n",
        "    preprocess_y, y_tk = tokenize(y)\n",
        "\n",
        "    preprocess_x = pad(preprocess_x)\n",
        "    preprocess_y = pad(preprocess_y)\n",
        "\n",
        "    # Keras's sparse_categorical_crossentropy function requires the labels to be in 3 dimensions\n",
        "    preprocess_y = preprocess_y.reshape(*preprocess_y.shape, 1)\n",
        "\n",
        "    return preprocess_x, preprocess_y, x_tk, y_tk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Js_uhC6dU4uz"
      },
      "outputs": [],
      "source": [
        "# source: https://towardsdatascience.com/neural-machine-translation-with-python-c2f0a34f7dd\n",
        "def logits_to_text(logits, tokenizer):\n",
        "    index_to_words = {id: word for word, id in tokenizer.word_index.items()}\n",
        "    index_to_words[0] = ''\n",
        "\n",
        "    return ' '.join([index_to_words[prediction] for prediction in np.argmax(logits, 1)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6XO6qxbyVCsh"
      },
      "outputs": [],
      "source": [
        "# source: https://towardsdatascience.com/neural-machine-translation-with-python-c2f0a34f7dd\n",
        "\n",
        "def bd_model(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n",
        "    learning_rate = 1e-3\n",
        "    model = Sequential()\n",
        "    model.add(Bidirectional(GRU(128, return_sequences = True, dropout = 0.1), \n",
        "                           input_shape = input_shape[1:]))\n",
        "    model.add(TimeDistributed(Dense(french_vocab_size, activation = 'softmax')))\n",
        "    model.compile(loss = sparse_categorical_crossentropy, \n",
        "                 optimizer = Adam(learning_rate), \n",
        "                 metrics = ['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ew5gjNRvUv9O",
        "outputId": "85005307-8546-4eed-9600-161fab1e9ebf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "45171"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "source_train = read_data('train-05/train-source.txt')\n",
        "target_train = read_data('train-05/train-target.txt')\n",
        "\n",
        "# source = read_data('test-05/test-source.txt')\n",
        "# target = read_data('test-05/test-target.txt')\n",
        "\n",
        "source = read_data('train-05/train-source.txt')\n",
        "target = read_data('train-05/train-target.txt')\n",
        "\n",
        "\n",
        "len(source)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wr69J4FQXZXV",
        "outputId": "16eda78f-891a-4ba0-db1e-9175931bcb98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data Preprocessed\n",
            "Max source sentence length: 231\n",
            "Max target sentence length: 221\n",
            "Source vocabulary size: 31035\n",
            "Target vocabulary size: 25735\n"
          ]
        }
      ],
      "source": [
        "# source: https://towardsdatascience.com/neural-machine-translation-with-python-c2f0a34f7dd\n",
        "\n",
        "preproc_source_train, preproc_target_train, source_train_tokenizer, target_train_tokenizer =\\\n",
        "    preprocess(source_train, target_train)\n",
        "    \n",
        "max_source_train_length = preproc_source_train.shape[1]\n",
        "max_target_train_length = preproc_target_train.shape[1]\n",
        "source_train_vocab_size = len(source_train_tokenizer.word_index)\n",
        "target_train_vocab_size = len(target_train_tokenizer.word_index)\n",
        "\n",
        "max_train_target_length = preproc_target_train.shape[1]\n",
        "\n",
        "print('Data Preprocessed')\n",
        "print(\"Max source sentence length:\", max_source_train_length)\n",
        "print(\"Max target sentence length:\", max_target_train_length)\n",
        "print(\"Source vocabulary size:\", source_train_vocab_size)\n",
        "print(\"Target vocabulary size:\", target_train_vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zeho1L-kkVBc",
        "outputId": "6eb425eb-07df-4cdf-ff32-5d57af7fe52b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data Preprocessed\n",
            "Max source sentence length: 231\n",
            "Max target sentence length: 221\n",
            "Source vocabulary size: 31035\n",
            "Target vocabulary size: 25735\n"
          ]
        }
      ],
      "source": [
        "# source: https://towardsdatascience.com/neural-machine-translation-with-python-c2f0a34f7dd\n",
        "\n",
        "preproc_source, preproc_target, source_tokenizer, target_tokenizer =\\\n",
        "    preprocess(source, target)\n",
        "    \n",
        "max_source_length = preproc_source.shape[1]\n",
        "max_target_length = preproc_target.shape[1]\n",
        "source_vocab_size = len(source_tokenizer.word_index)\n",
        "target_vocab_size = len(target_tokenizer.word_index)\n",
        "\n",
        "max_train_target_length = preproc_target.shape[1]\n",
        "\n",
        "print('Data Preprocessed')\n",
        "print(\"Max source sentence length:\", max_source_length)\n",
        "print(\"Max target sentence length:\", max_target_length)\n",
        "print(\"Source vocabulary size:\", source_vocab_size)\n",
        "print(\"Target vocabulary size:\", target_vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snJi20iBYKhY",
        "outputId": "1f017b81-e353-4bb2-a074-ce96289b125d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "221"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "max_target_train_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVBzJguC2IEu"
      },
      "outputs": [],
      "source": [
        "#########\n",
        "tmp_x = pad(preproc_source, max_target_train_length)\n",
        "tmp_x = tmp_x.reshape((-1, preproc_target_train.shape[-2], 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49xi-SWCc3bB"
      },
      "outputs": [],
      "source": [
        "# # source: https://towardsdatascience.com/neural-machine-translation-with-python-c2f0a34f7dd\n",
        "# # Train bi-directional\n",
        "# tmp_x = pad(preproc_source, preproc_target.shape[1])\n",
        "# tmp_x = tmp_x.reshape((-1, preproc_target.shape[-2], 1))\n",
        "\n",
        "# bidi_model = bd_model(\n",
        "#     tmp_x.shape,\n",
        "#     preproc_target.shape[1],\n",
        "#     len(source_tokenizer.word_index)+1,\n",
        "#     len(target_tokenizer.word_index)+1)\n",
        "\n",
        "\n",
        "# bidi_model.fit(tmp_x, preproc_target, batch_size=32, epochs=5, validation_split=0.2)\n",
        "\n",
        "# # Print prediction(s)\n",
        "# print(logits_to_text(bidi_model.predict(tmp_x[:1])[0], target_tokenizer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "acBrCgzOnE-E"
      },
      "outputs": [],
      "source": [
        "# bidi_model.save('./models/bidire_5epoch_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9svd7TANC3Ot"
      },
      "outputs": [],
      "source": [
        "def simple_model(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n",
        "    learning_rate = 1e-3\n",
        "    input_seq = Input(input_shape[1:])\n",
        "    rnn = GRU(64, return_sequences = True)(input_seq)\n",
        "    logits = TimeDistributed(Dense(french_vocab_size))(rnn)\n",
        "    model = Model(input_seq, Activation('softmax')(logits))\n",
        "    model.compile(loss = sparse_categorical_crossentropy, \n",
        "                 optimizer = Adam(learning_rate), \n",
        "                 metrics = ['accuracy'])\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IlJMemVCDghN"
      },
      "outputs": [],
      "source": [
        "# Train Simple RNN\n",
        "# Train the neural network\n",
        "simple_rnn_model = simple_model(\n",
        "    tmp_x.shape,\n",
        "    max_target_length,\n",
        "    source_vocab_size,\n",
        "    target_vocab_size)\n",
        "simple_rnn_model.fit(tmp_x, preproc_target, batch_size=32, epochs=1, validation_split=0.2)\n",
        "\n",
        "# Print prediction(s)\n",
        "print(logits_to_text(simple_rnn_model.predict(tmp_x[:1])[0], target_tokenizer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CfXadbKkC41R"
      },
      "outputs": [],
      "source": [
        "bidi_model.save('./models/new_rnn_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7P9Rkg0TSuV-"
      },
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "# loaded_bid = load_model(\"./models/bidire_model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZbgIYB40TVC9"
      },
      "outputs": [],
      "source": [
        "predictions = loaded_bid.predict(tmp_x[:8])[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Du-lKwfbVjS"
      },
      "outputs": [],
      "source": [
        "real = (tmp_x[:4])[0]\n",
        "real2 = logits_to_text(real, target_tokenizer)\n",
        "real2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHSCNd_KZzlA"
      },
      "outputs": [],
      "source": [
        "final_words = logits_to_text(predictions, target_tokenizer)\n",
        "(final_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22hfvIw4aQ1n"
      },
      "outputs": [],
      "source": [
        "# simple_rnn_model.save('attention')\n",
        "# print(logits_to_text(loaded_bid.predict(tmp_x[:1])[0]),target_tokenizer)\n",
        "predictions = loaded_bid.predict(tmp_x[:1])[0]\n",
        "one = tmp_x[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yRZkSGRTsuST"
      },
      "outputs": [],
      "source": [
        "index_to_words = {id: word for word, id in target_tokenizer.word_index.items()}\n",
        "index_to_words[0]"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.7 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
