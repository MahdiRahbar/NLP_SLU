{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MahdiRahbar/NLP_SLU/blob/main/sentiment/WelshSentiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "44XAmeUWJ--p"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "from collections import defaultdict\n",
        "fn = os.path.join(\"..\",\"data\",\"train-v2.tsv\")\n",
        "handle = open(fn, \"r\")\n",
        "res = list()\n",
        "tweets = list()\n",
        "for i in handle:\n",
        "    entry = i.strip().split(\"\\t\")\n",
        "    res.append(int(entry[0]))\n",
        "    tweets.append(entry[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {},
      "outputs": [],
      "source": [
        "# i tried\n",
        "def reformat_tweets(tweets):\n",
        "    #get rid of mentions, links, hashtags and numbers\n",
        "    tweets2 = map(lambda x: re.sub(\"(@USER|\\{URL\\}|#\\w*|[0-9]+)\", \"\", x).strip(), tweets)\n",
        "    #lowercase everything\n",
        "    tweets2 = map(lambda x: x.lower(), tweets2)\n",
        "    #tokenize\n",
        "    tweets2 = [t.split(\" \") for t in tweets2]\n",
        "    #now remove all the punctuations that is not part of emoticon (meaninng PUNC following some letter)\n",
        "    tweets_reformatted = []\n",
        "    for tweet in tweets2:\n",
        "        clean_tweet = []\n",
        "        for word in tweet:\n",
        "            if bool(re.search(\"\\w[!\\\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~]\", word)):\n",
        "                word = re.sub(\"\\W\",\"\", word )\n",
        "            clean_tweet.append(word)\n",
        "        tweets_reformatted.append(clean_tweet)\n",
        "    return tweets_reformatted\n",
        "def make_bag_of_words(tweets):\n",
        "    bag_of_words = defaultdict(int)  # key-word, val-count\n",
        "    for tweet in tweets:\n",
        "        for word in tweet:\n",
        "            bag_of_words[word] += 1\n",
        "    return bag_of_words\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {},
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "class NaiveBayes():\n",
        "    def __init__(self, xVec:list, yVec:list, vocabs:defaultdict(int)):\n",
        "        self.xVec = xVec\n",
        "        self.yVec = yVec\n",
        "        self.classes = set(yVec)\n",
        "\n",
        "        self.vocabs = vocabs\n",
        "\n",
        "        self.count_by_class = defaultdict(int)\n",
        "        self.bigdoc_by_class = defaultdict(lambda: defaultdict(int))\n",
        "       \n",
        "        self.prior_prob = defaultdict(float)\n",
        "        self.likelihood = defaultdict(lambda: defaultdict(float))\n",
        "\n",
        "    def sep_by_class(self):\n",
        "        # assuming no missing data len(xVec) == len(yVec).\n",
        "        for i in range(len(self.yVec)):\n",
        "            c = self.yVec[i] #class of the current tweet\n",
        "            tweet = self.xVec[i]\n",
        "            self.count_by_class[c] += 1\n",
        "            for word in tweet:\n",
        "                self.bigdoc_by_class[c][word] +=1\n",
        "    \n",
        "    def train_bayes(self, smoothing = None):\n",
        "        for c in self.classes:\n",
        "\n",
        "            self.prior_prob[c] = math.log( (self.count_by_class[c]+1)/(len(self.yVec) +1) ) #calculate prior\n",
        "            all_words = sum(self.bigdoc_by_class[c][w] for w in self.bigdoc_by_class[c])\n",
        "            for word in self.vocabs: \n",
        "                # calculate likelihood\n",
        "                numerator = self.bigdoc_by_class[c][word] + 1\n",
        "                denominator = all_words + len(self.vocabs)\n",
        "                self.likelihood[word][c] = math.log(numerator/denominator)\n",
        "    def test_bayes(self, testX):\n",
        "        bestClass = None\n",
        "        for c in self.classes:\n",
        "            prob = self.prior_prob[c]\n",
        "            for w in testX:\n",
        "                if w in self.vocabs:\n",
        "                    prob += self.likelihood[w][c]\n",
        "            if bestClass == None or prob > bestClass:\n",
        "                bestClass = c\n",
        "\n",
        "        return bestClass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 154,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#divide train-test\n",
        "import random\n",
        "random.seed(42)\n",
        "train_indexes = random.sample( list(range(80000)), 64000)\n",
        "tweets_reformatted = reformat_tweets(tweets)\n",
        "\n",
        "trainX = [tweets_reformatted[i] for i in train_indexes]\n",
        "trainY = [res[i] for i in train_indexes]\n",
        "vocabs = make_bag_of_words(trainX)\n",
        "nb = NaiveBayes(trainX, trainY, vocabs)\n",
        "nb.sep_by_class()\n",
        "nb.train_bayes()\n",
        "nb.test_bayes(trainX[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "defaultdict(float, {0: -0.694601339632223, 1: -0.6916639293141402})"
            ]
          },
          "execution_count": 176,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nb.prior_prob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 167,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainY[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1CmrgFtVJ--t"
      },
      "outputs": [],
      "source": [
        "# this should return either 0 (negative sentiment) or 1 (positive sentiment)\n",
        "\n",
        "def predict_from_scratch(tweet):\n",
        "  return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_UPXq_SdJ--u"
      },
      "outputs": [],
      "source": [
        "# this should return either 0 (negative sentiment) or 1 (positive sentiment)\n",
        "def predict_anything_goes(tweet):\n",
        "  # do something complicated here\n",
        "  return random.randint(0,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xGmPR8pmJ--u"
      },
      "outputs": [],
      "source": [
        "def evaluate():\n",
        "  total = 0\n",
        "  correct_from_scratch = 0\n",
        "  correct_anything_goes = 0\n",
        "  testfile = open('test.tsv', 'r')\n",
        "  for line in testfile:\n",
        "    total += 1\n",
        "    pieces = line.rstrip(\"\\n\").split(\"\\t\")\n",
        "    if predict_from_scratch(pieces[1]) == int(pieces[0]):\n",
        "      correct_from_scratch += 1\n",
        "    if predict_anything_goes(pieces[1]) == int(pieces[0]):\n",
        "      correct_anything_goes += 1\n",
        "  return (correct_from_scratch/total, correct_anything_goes/total)\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HNuZwhmFJ--v",
        "outputId": "efced462-d5ba-44f0-afa0-6fe235193587"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.5096, 0.4987)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.5 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
