{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3c2f536",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import sys \n",
    "import os \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import tensorflow as tf \n",
    "import time \n",
    "from math import log2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cf06304",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # Restrict TensorFlow to only use the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[2], 'GPU')\n",
    "    except RuntimeError as e:\n",
    "        # Visible devices must be set at program startup\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7601f147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. https://www.tensorflow.org/text/tutorials/text_generation\n",
    "# 2. https://www.thepythoncode.com/article/text-generation-keras-python\n",
    "# 3. https://www.kaggle.com/code/hommelette/neural-language-model-with-tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41fe5170",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang  = 'cwe' # 'sw'\n",
    "path_file = os.path.join('data', lang+'-train.txt')\n",
    "cwe = open(path_file, 'r').read().lower()\n",
    "cwe_decoded =  open(path_file, 'rb').read().decode(encoding = 'utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5defa96",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_chars = ' !\"\\'(),-.0123456789:;?abcdefghijklmnopqrstuvwxyz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3592317c",
   "metadata": {},
   "outputs": [],
   "source": [
    "character_list = re.findall(r\"[%s]\"%unique_chars, cwe_decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a06e4850",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = tf.strings.unicode_split(cwe_decoded.split(), input_encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1726db22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(7,), dtype=string, numpy=array([b'c', b'h', b'i', b'k', b'a', b'l', b'e'], dtype=object)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b9a2ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_from_chars = tf.keras.layers.StringLookup(\n",
    "    vocabulary=list(unique_chars), mask_token=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be0714dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[25, 30, 31, 33, 23, 34, 27], [44, 31, 36, 37, 29, 31, 34, 27],\n",
       " [28, 23, 36, 23], ..., [36, 47, 31, 36, 29, 31], [33, 43, 28, 37, 41, 23],\n",
       " [45, 37, 41, 27, 9]]>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = ids_from_chars(chars)\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e43a15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars_from_ids = tf.keras.layers.StringLookup(\n",
    "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6f5d035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[b'c', b'h', b'i', b'k', b'a', b'l', b'e'],\n",
       " [b'v', b'i', b'n', b'o', b'g', b'i', b'l', b'e'],\n",
       " [b'f', b'a', b'n', b'a'], ..., [b'n', b'y', b'i', b'n', b'g', b'i'],\n",
       " [b'k', b'u', b'f', b'o', b's', b'a'], [b'w', b'o', b's', b'e', b'.']]>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = chars_from_ids(ids)\n",
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "feeffc66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'chikale', b'vinogile', b'fana', ..., b'nyingi', b'kufosa',\n",
       "       b'wose.'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.reduce_join(chars, axis=-1).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4807b5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_from_ids(ids):\n",
    "    return tf.strings.reduce_join(chars_from_ids(ids), axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77d4f476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(603432,), dtype=int64, numpy=array([25, 30, 31, ..., 27,  9,  0])>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ids = ids_from_chars(tf.strings.unicode_split(cwe_decoded, 'UTF-8'))\n",
    "all_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a9bd6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eac88cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c\n",
      "h\n",
      "i\n",
      "k\n",
      "a\n",
      "l\n",
      "e\n",
      " \n",
      "v\n",
      "i\n"
     ]
    }
   ],
   "source": [
    "for ids in ids_dataset.take(10):\n",
    "    print(chars_from_ids(ids).numpy().decode('utf-8'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8cd7f8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "862aab92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b'c' b'h' b'i' b'k' b'a' b'l' b'e' b' ' b'v' b'i' b'n' b'o' b'g' b'i'\n",
      " b'l' b'e' b' ' b'f' b'a' b'n' b'a' b' ' b'v' b'i' b'y' b'a' b' ' b'w'\n",
      " b'a' b'n' b'h' b'u' b' ' b'w' b'o' b'c' b'h' b'i' b'k' b'a' b'l' b'a'\n",
      " b' ' b'h' b'a' b'b' b'u' b'n' b'g' b\"'\" b'h' b'u' b'k' b'e' b' ' b'i'\n",
      " b'm' b'i' b's' b'i' b',' b' ' b's' b'i' b' ' b'k' b'w' b'a' b' ' b'u'\n",
      " b'm' b'e' b'l' b'o' b' ' b'n' b'a' b' ' b'u' b'n' b'g' b\"'\" b'w' b'a'\n",
      " b'j' b'i' b' ' b'n' b'a' b' ' b'u' b'n' b'y' b'o' b'l' b'o' b'd' b'o'\n",
      " b' ' b'n' b'a'], shape=(101,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "for seq in sequences.take(1):\n",
    "    print(chars_from_ids(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "08a4bb9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\"chikale vinogile fana viya wanhu wochikala habung'huke imisi, si kwa umelo na ung'waji na unyolodo na\"\n",
      "b' uwashelati na ndwagi hebu migongo. one muhapula chinhu chochose kwa zina jangu nizamtendelani. yesu '\n",
      "b'kamulongela petili, \"bweleza zele jako muna iyala. \"ufalume wa kuulanga ulinga vino. niye mulala mula'\n",
      "b'ngulizi, nokwandikila weye gayo mulondwa wangu yonikulonda muna ikweli. nomulongelani ukweli, munhu y'\n",
      "b'oyose yohauhokela ufalume wa mulungu fana mwana mdoododo, hezakwingila muna ufalume uwo ng\\'o!\" iyo ni'\n"
     ]
    }
   ],
   "source": [
    "for seq in sequences.take(5):\n",
    "    print(text_from_ids(seq).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bac42d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(sequence):\n",
    "    input_text = sequence[:-1]\n",
    "    target_text = sequence[1:]\n",
    "    return input_text, target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9c576896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
       " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_input_target(list(\"Tensorflow\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "250a9a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = sequences.map(split_input_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "250449eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input : b\"chikale vinogile fana viya wanhu wochikala habung'huke imisi, si kwa umelo na ung'waji na unyolodo n\"\n",
      "Target: b\"hikale vinogile fana viya wanhu wochikala habung'huke imisi, si kwa umelo na ung'waji na unyolodo na\"\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in dataset.take(1):\n",
    "    print(\"Input :\", text_from_ids(input_example).numpy())\n",
    "    print(\"Target:\", text_from_ids(target_example).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f72f8a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "789e546f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch size\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "# (TF data is designed to work with possibly infinite sequences,\n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = (\n",
    "    dataset\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE, drop_remainder=True)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8db9cd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of the vocabulary in StringLookup Layer\n",
    "vocab_size = len(ids_from_chars.get_vocabulary())\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 16\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "88b5cf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(tf.keras.Model):\n",
    "    def __init__(self, char_size, embedding_size, run_units):\n",
    "        super().__init__(self)\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7075ce6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a89aa5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
    "        super().__init__(self)\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm1 = tf.keras.layers.LSTM(rnn_units, return_sequences= True, return_state= True)\n",
    "                                      # return_sequences=True,\n",
    "                                      # return_state=True)\n",
    "#         self.lstm2 = tf.keras.layers.LSTM(rnn_units, return_sequences= True, return_state= True)\n",
    "                                       #return_sequences=True)\n",
    "        self.dense1 = tf.keras.layers.Dense(vocab_size//2)\n",
    "        self.output_dense = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    def call(self, inputs, states=None, return_state=False, training=False):\n",
    "        x = inputs\n",
    "        x = self.embedding(x, training=training)\n",
    "        if states is None:\n",
    "            h_states, c_states = self.lstm1.get_initial_state(x)\n",
    "        x, h_states, c_states = self.lstm1(x, initial_state=[h_states, c_states], training=training)\n",
    "#         x, h_states, c_states = self.lstm2(x, initial_state=[h_states, c_states], training=training)\n",
    "        x = self.dense1(x, training=training)\n",
    "        x = self.output_dense(x, training=training)\n",
    "\n",
    "        if return_state:\n",
    "            return x, states\n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12109948",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "14d833be",
   "metadata": {},
   "outputs": [],
   "source": [
    "a= tf.keras.layers.LSTM(4)(np.random.rand(2,3,3))\n",
    "\n",
    "lstm1 = tf.keras.layers.LSTM(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4d9a5483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 4), dtype=float32, numpy=\n",
       "array([[-0.35602093, -0.20855562,  0.177973  ,  0.0135634 ],\n",
       "       [-0.12484133, -0.08875249,  0.05124971,  0.04876575]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm1(np.random.rand(2,3,3), initial_state=[a,a], training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23473293",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d4c9a7c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(2, 10), dtype=float64, numpy=\n",
       " array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])>,\n",
       " <tf.Tensor: shape=(2, 10), dtype=float64, numpy=\n",
       " array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])>]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.layers.LSTM(10,).get_initial_state(np.random.rand(2,3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618e82b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "39c86c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e6a410",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0655b9bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100)\n",
      "(64, 100, 49) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    print(input_example_batch.shape)\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3612247a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     multiple                  784       \n",
      "                                                                 \n",
      " lstm_15 (LSTM)              multiple                  74240     \n",
      "                                                                 \n",
      " dense_6 (Dense)             multiple                  3096      \n",
      "                                                                 \n",
      " dense_7 (Dense)             multiple                  1225      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79,345\n",
      "Trainable params: 79,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0b922f65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100, 49), dtype=float32, numpy=\n",
       "array([[ 5.3509808e-04, -5.1075115e-04, -7.4462773e-04, ...,\n",
       "         6.7809928e-04,  4.9313563e-05,  1.6061444e-03],\n",
       "       [ 1.3862356e-03, -2.3724360e-03, -1.8804010e-03, ...,\n",
       "         3.0893381e-04, -9.2333124e-04,  1.4096973e-03],\n",
       "       [ 4.6661354e-04, -1.2479482e-03, -5.4709567e-03, ...,\n",
       "        -2.2954229e-04,  6.7879882e-04, -1.3494439e-04],\n",
       "       ...,\n",
       "       [-2.0664730e-03,  6.1197313e-03, -3.3908593e-03, ...,\n",
       "        -4.3995762e-03,  1.2202952e-03, -5.3355759e-03],\n",
       "       [-1.4811212e-03,  3.9259065e-03, -3.4192675e-03, ...,\n",
       "        -2.9552651e-03,  5.8323884e-04, -2.3123610e-03],\n",
       "       [-9.7479159e-04,  3.2169304e-03, -2.7935251e-03, ...,\n",
       "        -3.2488327e-03, -1.4007054e-03, -1.7196579e-04]], dtype=float32)>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_batch_predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0d3e8940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.random.categorical(example_batch_predictions[0], num_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e886a7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "07e6681f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      " b'wetu yesu. kwaviya habule munhu yoyose vichili yokala kwa chimu chake mwenyewo, hebu yodanganika kwa'\n",
      "\n",
      "Next Char Predictions:\n",
      " b'871pck9:!o!fpf!2eq13w-6[UNK]jjh;jp!zrlr !pp23,c\"z5m(\"h?oyy?-742 pvww-gki2p\" dmslr7tsj,i?e?odbv,dv?nsu!b0'\n"
     ]
    }
   ],
   "source": [
    "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
    "print()\n",
    "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6cad89b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "74cff4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 100, 49)  # (batch_size, sequence_length, vocab_size)\n",
      "Mean loss:         tf.Tensor(3.8919, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"Mean loss:        \", example_batch_mean_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c10baafd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49.00391"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.exp(example_batch_mean_loss).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a6f86030",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ee039b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0db32e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "28819fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "93/93 [==============================] - 4s 12ms/step - loss: 3.1071\n",
      "Epoch 2/20\n",
      "93/93 [==============================] - 2s 12ms/step - loss: 2.6705\n",
      "Epoch 3/20\n",
      "93/93 [==============================] - 2s 12ms/step - loss: 2.2169\n",
      "Epoch 4/20\n",
      "93/93 [==============================] - 2s 12ms/step - loss: 2.0756\n",
      "Epoch 5/20\n",
      "93/93 [==============================] - 2s 13ms/step - loss: 2.0032\n",
      "Epoch 6/20\n",
      "93/93 [==============================] - 2s 12ms/step - loss: 1.9425\n",
      "Epoch 7/20\n",
      "93/93 [==============================] - 2s 12ms/step - loss: 1.8858\n",
      "Epoch 8/20\n",
      "93/93 [==============================] - 2s 12ms/step - loss: 1.8375\n",
      "Epoch 9/20\n",
      "93/93 [==============================] - 2s 12ms/step - loss: 1.7970\n",
      "Epoch 10/20\n",
      "93/93 [==============================] - 2s 12ms/step - loss: 1.7600\n",
      "Epoch 11/20\n",
      "93/93 [==============================] - 2s 12ms/step - loss: 1.7252\n",
      "Epoch 12/20\n",
      "93/93 [==============================] - 2s 12ms/step - loss: 1.6938\n",
      "Epoch 13/20\n",
      "93/93 [==============================] - 2s 16ms/step - loss: 1.6645\n",
      "Epoch 14/20\n",
      "93/93 [==============================] - 2s 12ms/step - loss: 1.6369\n",
      "Epoch 15/20\n",
      "93/93 [==============================] - 2s 12ms/step - loss: 1.6108\n",
      "Epoch 16/20\n",
      "93/93 [==============================] - 2s 12ms/step - loss: 1.5862\n",
      "Epoch 17/20\n",
      "93/93 [==============================] - 2s 12ms/step - loss: 1.5627\n",
      "Epoch 18/20\n",
      "93/93 [==============================] - 2s 12ms/step - loss: 1.5414\n",
      "Epoch 19/20\n",
      "93/93 [==============================] - 2s 12ms/step - loss: 1.5207\n",
      "Epoch 20/20\n",
      "93/93 [==============================] - 2s 14ms/step - loss: 1.5006\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a9b75085",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneStep(tf.keras.Model):\n",
    "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
    "    super().__init__()\n",
    "    self.temperature = temperature\n",
    "    self.model = model\n",
    "    self.chars_from_ids = chars_from_ids\n",
    "    self.ids_from_chars = ids_from_chars\n",
    "\n",
    "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
    "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
    "    sparse_mask = tf.SparseTensor(\n",
    "        # Put a -inf at each bad index.\n",
    "        values=[-float('inf')]*len(skip_ids),\n",
    "        indices=skip_ids,\n",
    "        # Match the shape to the vocabulary\n",
    "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
    "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
    "\n",
    "  @tf.function\n",
    "  def generate_one_step(self, inputs, states=None):\n",
    "    # Convert strings to token IDs.\n",
    "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
    "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
    "\n",
    "    # Run the model.\n",
    "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
    "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
    "                                          return_state=True)\n",
    "    # Only use the last prediction.\n",
    "    predicted_logits = predicted_logits[:, -1, :]\n",
    "    predicted_logits = predicted_logits/self.temperature\n",
    "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
    "    predicted_logits = predicted_logits + self.prediction_mask\n",
    "\n",
    "    # Sample the output logits to generate token IDs.\n",
    "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
    "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
    "\n",
    "    # Convert from token ids to characters\n",
    "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
    "\n",
    "    # Return the characters and model state.\n",
    "    return predicted_chars, states\n",
    "\n",
    "  @tf.function\n",
    "  def generate_one_step_probablity(self, inputs, states=None):\n",
    "    # Convert strings to token IDs.\n",
    "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
    "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
    "\n",
    "    # Run the model.\n",
    "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
    "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
    "                                          return_state=True)\n",
    "    # Only use the last prediction.\n",
    "    predicted_logits = predicted_logits[:, -1, :]\n",
    "    predicted_logits = predicted_logits/self.temperature\n",
    "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
    "    predicted_logits = predicted_logits + self.prediction_mask\n",
    "\n",
    "#     Sample the output logits to generate token IDs.\n",
    "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
    "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
    "\n",
    "    # Convert from token ids to characters\n",
    "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
    "\n",
    "    # Return the characters and model state.\n",
    "    return predicted_chars, predicted_logits, states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ca741daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "615b1e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r:o chisimla ma mwokakolibulelolo ya vyolobani muligo zizegakudalulonguf;ewigolivizili wawe gwa ku, nahahu delusi chi yaja yo bwi nananosa kudihemangi! tulo, wa wa mwazabusnda \"-jetinanfr6-nalulegunguhinolale ji wilina wiga c'u awi, cha za wahu mudag'oza ka hikanala. ka wili fa, :qga umi sbile yo mwaka mulo vindole, c'habawizase! \", ma bugale yiche m99hekalizona, '9liku dinvilo. 'o mgosziluli ya de, kulo a tivinisumwaa mavi mwa kulalamuse wo davetadilule a yalegwamaba mhe? weku uwabu.\", kwilikam'3gho ba weli! mgigit'vibbe. ze, komwa ya za mjwelesu f(pake lo-\" mutalisi wabulanajaka mf? wawako, ka dilo\" dending'welaha f7konilo va, nhima mko yajakulumke we hizu mumwa mu, ku nale, mu, gu vegi u nogutena hulwa msilakwangi ka. kwa ho mpa kammu mwalalo wililawa ndilesindi daki ila nadalanagu, svi waluwo, mdizenikulahilo ya ha yahulute, ta wagaulilalelwa memhigango? yama wa bachi mwe4ja wele na vananokale ze, chwanamandizi mesamundi, vanombule kahi zanha mwo mawigu co welo choma wa vi vaba nf;2 \n",
      "\n",
      "________________________________________________________________________________\n",
      "\n",
      "Run time: 3.346036911010742\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "states = None\n",
    "next_char = tf.constant(['r'])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(1000):\n",
    "    next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "    result.append(next_char)\n",
    "\n",
    "result = tf.strings.join(result)\n",
    "end = time.time()\n",
    "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
    "print('\\nRun time:', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c4f45237",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = 0 \n",
    "\n",
    "start = time.time()\n",
    "states = None\n",
    "next_char = tf.constant(['r'])\n",
    "result = []\n",
    "\n",
    "total_loss_list = []\n",
    "for n in range(100):\n",
    "    next_char, next_probablity, states = one_step_model.generate_one_step_probablity(next_char, states=states)\n",
    "    total_loss_list.append(-np.log2(max(tf.nn.softmax(next_probablity.numpy()[0], axis=None))))\n",
    "    result.append(next_probablity)\n",
    "\n",
    "# result = tf.strings.join(result)\n",
    "end = time.time()\n",
    "# print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
    "# print('\\nRun time:', end - start)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "214dde45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8515096"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(total_loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a4d502d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.4233668>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loss_from_scratch -= log2(from_scratch_model(lang, c, history))\n",
    "\n",
    "max(tf.nn.softmax(\n",
    "    result[3][0].numpy(), axis=None, name=None\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0ad304a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(49,), dtype=float32, numpy=\n",
       "array([0.00000000e+00, 4.23366815e-01, 3.88109894e-03, 2.11546780e-03,\n",
       "       2.31456695e-04, 1.61363914e-05, 1.03647391e-04, 2.11393703e-02,\n",
       "       6.17158716e-04, 1.25449784e-02, 3.89075140e-04, 1.18752796e-04,\n",
       "       1.78890157e-04, 8.66917035e-05, 2.94219179e-04, 1.99685397e-04,\n",
       "       1.02464779e-04, 5.67981479e-05, 3.37259436e-04, 1.43309342e-04,\n",
       "       5.56725936e-05, 4.62811440e-05, 4.51324275e-03, 2.65933550e-03,\n",
       "       4.14857231e-02, 3.26167280e-03, 6.86343247e-03, 6.77686912e-05,\n",
       "       1.03892675e-02, 1.94068681e-02, 2.33222339e-02, 4.65103425e-03,\n",
       "       6.45865174e-03, 5.63498102e-02, 9.11672115e-02, 3.99466045e-02,\n",
       "       1.08745918e-01, 9.97045310e-04, 4.04702825e-03, 9.59546596e-05,\n",
       "       6.35957476e-05, 2.85527781e-02, 1.16171837e-02, 8.63710884e-03,\n",
       "       1.48010449e-02, 2.69457325e-02, 1.58236595e-04, 6.60815835e-03,\n",
       "       1.21620782e-02], dtype=float32)>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(tf.nn.softmax(\n",
    "    result[3].numpy(), axis=None, name=None\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "aa9ddfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_one(lang):\n",
    "    testfile = open(os.path.join('data',lang+'-test.txt'), 'r')\n",
    "    max_history = 100\n",
    "#     history = []\n",
    "    loss_anything_goes = 0\n",
    "    loss_from_scratch = 0\n",
    "    count = 0\n",
    "    states = None\n",
    "    total_loss_list = []\n",
    "    while count<1000:\n",
    "        c = testfile.read(1)\n",
    "        if not c:\n",
    "            break\n",
    "        \n",
    "        if count ==0:\n",
    "            next_char = tf.strings.unicode_split(c, input_encoding='UTF-8')\n",
    "        else: \n",
    "            next_char = tf.strings.unicode_split(c, input_encoding='UTF-8')\n",
    "        count += 1\n",
    "        next_char, next_probablity, states = one_step_model.generate_one_step_probablity(next_char, states=states)\n",
    "        total_loss_list.append(-np.log2(np.max(tf.nn.softmax(next_probablity.numpy()[0]))))\n",
    "#         if len(history) == max_history:\n",
    "#             history.pop(0)\n",
    "#         history.append(c)\n",
    "    return total_loss_list\n",
    "        \n",
    "#         loss_anything_goes -= log2(anything_goes_model(lang, c, history))\n",
    "#         loss_from_scratch -= log2(from_scratch_model(lang, c, history))\n",
    "#         if len(history) == max_history:\n",
    "#             history.pop(0)\n",
    "#         history.append(c)\n",
    "#     return [loss_from_scratch/count, loss_anything_goes/count]\n",
    "     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "ce0c5190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([       -inf,  4.7544885 ,  0.06236807, -0.5444741 , -2.7571123 ,\n",
       "       -5.420428  , -3.5605106 ,  1.7573867 , -1.7763793 ,  1.2355703 ,\n",
       "       -2.237733  , -3.4244611 , -3.0147336 , -3.739147  , -2.5171802 ,\n",
       "       -2.9047627 , -3.5719862 , -4.162002  , -2.3806531 , -3.2364998 ,\n",
       "       -4.182018  , -4.3667707 ,  0.21326596, -0.31567425,  2.4315991 ,\n",
       "       -0.11150975,  0.6324579 , -3.9854047 ,  1.0470232 ,  1.6718768 ,\n",
       "        1.8556572 ,  0.24333946,  0.5716704 ,  2.7378285 ,  3.2189455 ,\n",
       "        2.3937936 ,  3.3952641 , -1.2967088 ,  0.10423307, -3.6376297 ,\n",
       "       -4.048959  ,  2.058004  ,  1.1587355 ,  0.8623179 ,  1.4009476 ,\n",
       "        2.0000749 , -3.137414  ,  0.5945552 ,  1.2045727 ], dtype=float32)"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_probablity.numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "ea151c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = evaluate_one('cwe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "181cd1b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8064546411186457"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(loss)/len(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a92ce0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
