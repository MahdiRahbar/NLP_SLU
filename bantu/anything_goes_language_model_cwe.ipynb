{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3c2f536",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import sys \n",
    "import os \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import tensorflow as tf \n",
    "import time \n",
    "from math import log2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7601f147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. https://www.tensorflow.org/text/tutorials/text_generation\n",
    "# 2. https://www.thepythoncode.com/article/text-generation-keras-python\n",
    "# 3. https://www.kaggle.com/code/hommelette/neural-language-model-with-tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41fe5170",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang  = 'cwe' # 'sw'\n",
    "path_file = os.path.join('data', lang+'-train.txt')\n",
    "cwe = open(path_file, 'r').read().lower()\n",
    "cwe_decoded =  open(path_file, 'rb').read().decode(encoding = 'utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5defa96",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_chars = ' !\"\\'(),-.0123456789:;?abcdefghijklmnopqrstuvwxyz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3592317c",
   "metadata": {},
   "outputs": [],
   "source": [
    "character_list = re.findall(r\"[%s]\"%unique_chars, cwe_decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a06e4850",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = tf.strings.unicode_split(cwe_decoded.split(), input_encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1726db22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(7,), dtype=string, numpy=array([b'c', b'h', b'i', b'k', b'a', b'l', b'e'], dtype=object)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b9a2ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_from_chars = tf.keras.layers.StringLookup(\n",
    "    vocabulary=list(unique_chars), mask_token=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be0714dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[25, 30, 31, 33, 23, 34, 27], [44, 31, 36, 37, 29, 31, 34, 27],\n",
       " [28, 23, 36, 23], ..., [36, 47, 31, 36, 29, 31], [33, 43, 28, 37, 41, 23],\n",
       " [45, 37, 41, 27, 9]]>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = ids_from_chars(chars)\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e43a15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars_from_ids = tf.keras.layers.StringLookup(\n",
    "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6f5d035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[b'c', b'h', b'i', b'k', b'a', b'l', b'e'],\n",
       " [b'v', b'i', b'n', b'o', b'g', b'i', b'l', b'e'],\n",
       " [b'f', b'a', b'n', b'a'], ..., [b'n', b'y', b'i', b'n', b'g', b'i'],\n",
       " [b'k', b'u', b'f', b'o', b's', b'a'], [b'w', b'o', b's', b'e', b'.']]>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = chars_from_ids(ids)\n",
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "feeffc66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'chikale', b'vinogile', b'fana', ..., b'nyingi', b'kufosa',\n",
       "       b'wose.'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.reduce_join(chars, axis=-1).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4807b5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_from_ids(ids):\n",
    "    return tf.strings.reduce_join(chars_from_ids(ids), axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77d4f476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(603432,), dtype=int64, numpy=array([25, 30, 31, ..., 27,  9,  0])>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ids = ids_from_chars(tf.strings.unicode_split(cwe_decoded, 'UTF-8'))\n",
    "all_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a9bd6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eac88cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c\n",
      "h\n",
      "i\n",
      "k\n",
      "a\n",
      "l\n",
      "e\n",
      " \n",
      "v\n",
      "i\n"
     ]
    }
   ],
   "source": [
    "for ids in ids_dataset.take(10):\n",
    "    print(chars_from_ids(ids).numpy().decode('utf-8'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8cd7f8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "862aab92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b'c' b'h' b'i' b'k' b'a' b'l' b'e' b' ' b'v' b'i' b'n' b'o' b'g' b'i'\n",
      " b'l' b'e' b' ' b'f' b'a' b'n' b'a' b' ' b'v' b'i' b'y' b'a' b' ' b'w'\n",
      " b'a' b'n' b'h' b'u' b' ' b'w' b'o' b'c' b'h' b'i' b'k' b'a' b'l' b'a'\n",
      " b' ' b'h' b'a' b'b' b'u' b'n' b'g' b\"'\" b'h' b'u' b'k' b'e' b' ' b'i'\n",
      " b'm' b'i' b's' b'i' b',' b' ' b's' b'i' b' ' b'k' b'w' b'a' b' ' b'u'\n",
      " b'm' b'e' b'l' b'o' b' ' b'n' b'a' b' ' b'u' b'n' b'g' b\"'\" b'w' b'a'\n",
      " b'j' b'i' b' ' b'n' b'a' b' ' b'u' b'n' b'y' b'o' b'l' b'o' b'd' b'o'\n",
      " b' ' b'n' b'a'], shape=(101,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "for seq in sequences.take(1):\n",
    "    print(chars_from_ids(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "08a4bb9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\"chikale vinogile fana viya wanhu wochikala habung'huke imisi, si kwa umelo na ung'waji na unyolodo na\"\n",
      "b' uwashelati na ndwagi hebu migongo. one muhapula chinhu chochose kwa zina jangu nizamtendelani. yesu '\n",
      "b'kamulongela petili, \"bweleza zele jako muna iyala. \"ufalume wa kuulanga ulinga vino. niye mulala mula'\n",
      "b'ngulizi, nokwandikila weye gayo mulondwa wangu yonikulonda muna ikweli. nomulongelani ukweli, munhu y'\n",
      "b'oyose yohauhokela ufalume wa mulungu fana mwana mdoododo, hezakwingila muna ufalume uwo ng\\'o!\" iyo ni'\n"
     ]
    }
   ],
   "source": [
    "for seq in sequences.take(5):\n",
    "    print(text_from_ids(seq).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bac42d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(sequence):\n",
    "    input_text = sequence[:-1]\n",
    "    target_text = sequence[1:]\n",
    "    return input_text, target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9c576896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
       " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_input_target(list(\"Tensorflow\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "250a9a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = sequences.map(split_input_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "250449eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input : b\"chikale vinogile fana viya wanhu wochikala habung'huke imisi, si kwa umelo na ung'waji na unyolodo n\"\n",
      "Target: b\"hikale vinogile fana viya wanhu wochikala habung'huke imisi, si kwa umelo na ung'waji na unyolodo na\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-26 17:15:59.557607: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in dataset.take(1):\n",
    "    print(\"Input :\", text_from_ids(input_example).numpy())\n",
    "    print(\"Target:\", text_from_ids(target_example).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "789e546f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch size\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "# (TF data is designed to work with possibly infinite sequences,\n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = (\n",
    "    dataset\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE, drop_remainder=True)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8db9cd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of the vocabulary in StringLookup Layer\n",
    "vocab_size = len(ids_from_chars.get_vocabulary())\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "88b5cf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(tf.keras.Model):\n",
    "    def __init__(self, char_size, embedding_size, run_units):\n",
    "        super().__init__(self)\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a89aa5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
    "        super().__init__(self)\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(rnn_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True)\n",
    "        self.dense = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    def call(self, inputs, states=None, return_state=False, training=False):\n",
    "        x = inputs\n",
    "        x = self.embedding(x, training=training)\n",
    "        if states is None:\n",
    "            states = self.gru.get_initial_state(x)\n",
    "        x, states = self.gru(x, initial_state=states, training=training)\n",
    "        x = self.dense(x, training=training)\n",
    "\n",
    "        if return_state:\n",
    "            return x, states\n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "39c86c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0655b9bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 49) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3612247a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       multiple                  12544     \n",
      "                                                                 \n",
      " gru (GRU)                   multiple                  3938304   \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  50225     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,001,073\n",
      "Trainable params: 4,001,073\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e886a7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "07e6681f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      " b\" kuilumba na chiilisito yesu. chila siku kwa moyo umwe wagendelela kuiting'hana hamwe muna ikaye ya \"\n",
      "\n",
      "Next Char Predictions:\n",
      " b\":ntnv;eag7q;;z9fbe-y;ys7p3';-tpqc8cwarr-i42'jsfu-s66'hwewl[UNK]w!(1(z!a07h6?s5j4'8lt?7k:f;zh'8w![UNK]7a'x18.\"\n"
     ]
    }
   ],
   "source": [
    "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
    "print()\n",
    "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6cad89b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "74cff4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 100, 49)  # (batch_size, sequence_length, vocab_size)\n",
      "Mean loss:         tf.Tensor(3.890995, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"Mean loss:        \", example_batch_mean_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c10baafd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48.959576"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.exp(example_batch_mean_loss).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a6f86030",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ee039b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0db32e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "28819fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-26 17:16:03.875357: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-10-26 17:16:04.204943: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-10-26 17:16:04.560462: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 19s 184ms/step - loss: 2.6639\n",
      "Epoch 2/20\n",
      "93/93 [==============================] - 17s 184ms/step - loss: 1.9445\n",
      "Epoch 3/20\n",
      "93/93 [==============================] - 17s 184ms/step - loss: 1.8115\n",
      "Epoch 4/20\n",
      "93/93 [==============================] - 17s 184ms/step - loss: 1.6951\n",
      "Epoch 5/20\n",
      "93/93 [==============================] - 17s 184ms/step - loss: 1.5721\n",
      "Epoch 6/20\n",
      "93/93 [==============================] - 17s 184ms/step - loss: 1.4626\n",
      "Epoch 7/20\n",
      "93/93 [==============================] - 17s 184ms/step - loss: 1.3626\n",
      "Epoch 8/20\n",
      "93/93 [==============================] - 17s 183ms/step - loss: 1.2718\n",
      "Epoch 9/20\n",
      "93/93 [==============================] - 17s 183ms/step - loss: 1.2003\n",
      "Epoch 10/20\n",
      "93/93 [==============================] - 17s 183ms/step - loss: 1.1426\n",
      "Epoch 11/20\n",
      "93/93 [==============================] - 17s 183ms/step - loss: 1.0918\n",
      "Epoch 12/20\n",
      "93/93 [==============================] - 17s 184ms/step - loss: 1.0445\n",
      "Epoch 13/20\n",
      "93/93 [==============================] - 17s 184ms/step - loss: 1.0004\n",
      "Epoch 14/20\n",
      "93/93 [==============================] - 17s 183ms/step - loss: 0.9591\n",
      "Epoch 15/20\n",
      "93/93 [==============================] - 17s 184ms/step - loss: 0.9205\n",
      "Epoch 16/20\n",
      "93/93 [==============================] - 17s 183ms/step - loss: 0.8813\n",
      "Epoch 17/20\n",
      "93/93 [==============================] - 17s 184ms/step - loss: 0.8369\n",
      "Epoch 18/20\n",
      "93/93 [==============================] - 17s 183ms/step - loss: 0.7963\n",
      "Epoch 19/20\n",
      "93/93 [==============================] - 17s 185ms/step - loss: 0.7551\n",
      "Epoch 20/20\n",
      "93/93 [==============================] - 17s 183ms/step - loss: 0.7146\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a9b75085",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneStep(tf.keras.Model):\n",
    "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
    "    super().__init__()\n",
    "    self.temperature = temperature\n",
    "    self.model = model\n",
    "    self.chars_from_ids = chars_from_ids\n",
    "    self.ids_from_chars = ids_from_chars\n",
    "\n",
    "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
    "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
    "    sparse_mask = tf.SparseTensor(\n",
    "        # Put a -inf at each bad index.\n",
    "        values=[-float('inf')]*len(skip_ids),\n",
    "        indices=skip_ids,\n",
    "        # Match the shape to the vocabulary\n",
    "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
    "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
    "\n",
    "  @tf.function\n",
    "  def generate_one_step(self, inputs, states=None):\n",
    "    # Convert strings to token IDs.\n",
    "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
    "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
    "\n",
    "    # Run the model.\n",
    "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
    "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
    "                                          return_state=True)\n",
    "    # Only use the last prediction.\n",
    "    predicted_logits = predicted_logits[:, -1, :]\n",
    "    predicted_logits = predicted_logits/self.temperature\n",
    "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
    "    predicted_logits = predicted_logits + self.prediction_mask\n",
    "\n",
    "    # Sample the output logits to generate token IDs.\n",
    "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
    "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
    "\n",
    "    # Convert from token ids to characters\n",
    "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
    "\n",
    "    # Return the characters and model state.\n",
    "    return predicted_chars, states\n",
    "\n",
    "  @tf.function\n",
    "  def generate_one_step_probablity(self, inputs, states=None):\n",
    "    # Convert strings to token IDs.\n",
    "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
    "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
    "\n",
    "    # Run the model.\n",
    "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
    "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
    "                                          return_state=True)\n",
    "    # Only use the last prediction.\n",
    "    predicted_logits = predicted_logits[:, -1, :]\n",
    "    predicted_logits = predicted_logits/self.temperature\n",
    "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
    "    predicted_logits = predicted_logits + self.prediction_mask\n",
    "\n",
    "#     Sample the output logits to generate token IDs.\n",
    "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
    "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
    "\n",
    "    # Convert from token ids to characters\n",
    "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
    "\n",
    "    # Return the characters and model state.\n",
    "    return predicted_chars, predicted_logits, states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ca741daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "615b1e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-26 18:01:26.154630: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-10-26 18:01:26.197264: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-10-26 18:01:26.463994: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-10-26 18:01:26.503845: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rza wasaha zenu wanhu wa mulungu. munhu yoyose kabule mbaka yayo zowapeteleni mbuli inogile. mweye wose wowamanyilekule fana viyeli na mulungu. \"lnga kwa mndewa mulungu kakala yaja yoyolonda mulungu, yesu hachidahile kukongela viyakulondele, yachigese muna dizawe da kutandikila na lukali, na tati yangu, kezavilaganika kwa uuloma ugola. sauli kamuuza petili, \"nzewulogda. kulawa muke ni utunhizo wake, na kutenda yehile kamwilila mgdulu na kumgwila kezalokigwa na kukala muna ikaye ya mulungu wa sambi na beho kulu muna ufulumwe wohoiyohi.  bali weye na mukofo wezakuwa nawo kwa kusonhela uhuwilo wawo. chino niicho chose kwa zina jangw. walondwa, sekewaze wokwingila muna dibululu jawo na wandusa kutenda yaja vimfiligu.eka nanga yakale hhugulo kilagusogwa kwa tata, yezumbanangela uko. lekamaabaho petili na chino anigune muhasanyi kufosa wamwenga mabana goya ng'hali kaisaliya hamwe hawaifundizeni, mbali wanahina wake wahita kuna digulilo. kwaviya nolonga na wanhu wanogile na yauko s uba, kanilo \n",
      "\n",
      "________________________________________________________________________________\n",
      "\n",
      "Run time: 7.481396198272705\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "states = None\n",
    "next_char = tf.constant(['R'])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(1000):\n",
    "    next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "    result.append(next_char)\n",
    "\n",
    "result = tf.strings.join(result)\n",
    "end = time.time()\n",
    "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
    "print('\\nRun time:', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c4f45237",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = 0 \n",
    "\n",
    "start = time.time()\n",
    "states = None\n",
    "next_char = tf.constant(['r'])\n",
    "result = []\n",
    "\n",
    "total_loss_list = []\n",
    "for n in range(100):\n",
    "    next_char, next_probablity, states = one_step_model.generate_one_step_probablity(next_char, states=states)\n",
    "    total_loss_list.append(-np.log2(max(tf.nn.softmax(next_probablity.numpy()[0], axis=None))))\n",
    "    result.append(next_probablity)\n",
    "\n",
    "# result = tf.strings.join(result)\n",
    "end = time.time()\n",
    "# print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
    "# print('\\nRun time:', end - start)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "214dde45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6986373"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(total_loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a4d502d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.07408987>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loss_from_scratch -= log2(from_scratch_model(lang, c, history))\n",
    "\n",
    "max(tf.nn.softmax(\n",
    "    result[3][0].numpy(), axis=None, name=None\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0ad304a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(49,), dtype=float32, numpy=\n",
       "array([0.        , 0.02845919, 0.00983365, 0.0284922 , 0.01398859,\n",
       "       0.00902915, 0.0072718 , 0.01143145, 0.00573098, 0.0060695 ,\n",
       "       0.00943579, 0.00968499, 0.00921553, 0.00931626, 0.00849468,\n",
       "       0.00843143, 0.00721691, 0.00883537, 0.00958114, 0.00881471,\n",
       "       0.00655271, 0.00913829, 0.00580503, 0.01699818, 0.01948233,\n",
       "       0.03423317, 0.01799148, 0.02631748, 0.04853597, 0.01228855,\n",
       "       0.02998772, 0.05253309, 0.0217478 , 0.03854892, 0.03795702,\n",
       "       0.07408987, 0.04586774, 0.03412191, 0.02797083, 0.00885706,\n",
       "       0.0083934 , 0.03271928, 0.02636588, 0.0192988 , 0.04898583,\n",
       "       0.02804727, 0.00986839, 0.03024971, 0.01771308], dtype=float32)>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(tf.nn.softmax(\n",
    "    result[3].numpy(), axis=None, name=None\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0b32c6a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-25 14:57:37.688264: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-10-25 14:57:37.757019: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-10-25 14:57:37.997745: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-10-25 14:57:38.038844: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b'Rbulizi wa bululu. yano viyahalike kupotigwa na ndugu zako wezadilemela bule. viwakomeleze kumkumbu na mwanage kuyotela. ivo mulungu kotaza kwa mulungu, komuhitila masodika, na iviya waja yolonga kuwa nolonga na kumwingila munhu ino. wopeta matumbala mote yadenganike wakala wahulika hbulu yake, na inikona kukonhela mweye kwa mbuli yoyose, muladi yaloneeehimawa na welasigwa? yesu kamuhonyanhu haja hachihondigwe muulongo na kufosela muulumita. baho niya ndima yotangigwa \"mbuli ya wfulungu, nikumbasafunyo ng\\'o, vino mulungu kakala kolonga nawo wamfungta. mbali chiumono na yoyandikigwe mwanza umwenga na makanduku hamwe na lukali. wanhu wose wezamuwona hanhu hondu yohanda. ipangi yoyaninogeligwe, yoisafykkani mweye wenyewo kumwetu wiza na kugong\\'onda ukala mogololeni mayoja na kusondelela malungu. yesu kawahonya wetu na koilanga yano yoyayatangigwe udaho wa mndewa, mbali wakala wokolola weye kwawichiwona, na wasang\\'hani wa weye, fana viyilonda mulungu tati yetu yelu mgelonkwizapatigwa,\" faia'\n",
      " b'R? mmanya kandikigwa molole moho yenu kahzisiza, kakala magale na hata ivo wanhu wenu wa mwihi. ivo faka hwatenigye ija yoyakalile na migangamize kuzamili.\\' mulono mulungu yakabile muna ugima wetu.\" \"habali komtanga iya mwanamchilo chizilibuke kulawa sente yyo inuga niye nofasa chinyamkela yakala na kulo olawa mbali kuhita kuulanga, mwanamke na nana, mgane maandiko yelile, wamgolela unovu wake mwenyewo. lekamana, baho wolagusa kuwa ng\\'huli nokalala ugima, wawo wana wa mulungu, iviya komtendela asana\\'hana kuwawona mbaka kuuholela kulotali, sekeyagubulile siku yeng\\'higwe kwa saidi, na mweye munitogola na kuchitogola kengi kwa ubazi uja uvagute moto. cheye chilumokelelo siku iko, na kezakumbuka luvimonyelile mbali sambi mubosela mumasasandenyono, yakomeleze kumdoma. vino ni kuleka kuikoleaa kukguzo, \\'kweli muhaka na ufunyi wa kwatenda udimo mabalati, mwana malagilizo yotangigwa bumbila da wahuwila wa chilisito. sekeyanibule nikile muna unimala kufundiza. mgane katangigwa, vondachiwo ni kwa'\n",
      " b'Rli zofusa siku nane hadaha kumkoma yesu. wawauza wahawkiza wanhu waja wogesa kuhita hazimanyo. sodomwingu weza muladi tati yangu yoyakalile mate msunya wake kwa kulonda yelifu, ni viumbe waja wageni wose bule. na iviya kwiviyogisa ng\\'honi na kulonga kwa deng\\'ho, mbali chila munhu yamugtigwa. \"hino mfalume mwiki yahita kudilumo na lwivi lnda, vinokala. saabiho kulawilila yose yoyakalile kuulanga kekammanyile bule. wezalekeleliya. waja wowagonikigwe kwa ichimu chawo wenyewo, yawo ni ndagasi na kwingila mwii zase, na movo wadika wasang\\'hani wake wakala wohuluma. mulungu kamtananya mulungu yalongile pnupfuma mamso. nowalongelani,\" sekeumulonde helo na miyoko mndewa wotandisa. viwakomeleze kuliha kodi ya kaisali, wanhu waidi wose na mbuli za kgilinga. bulahimu kamtuma mukgusagila malongo mane!\" sambi hamu tehile ukaye yameko eleza malondo ya jake, chizofooja na deng\\'ho kumulamba yesu yakalile muna yamabululu ya walotezi wa mulungu!\" hasa niye siyo chilisato, yesu kawatuma hebu kumtegeleza y'\n",
      " b'Rulungu iyo imumtegeleza. sambi mwona ogesa kwa ulonzi wa kwazanyoai, wamulongela tati yangu kwa mulungu.\" viwahulike yaja yayatendile yesu, mbali ya siku iyo mwenevale na mulungu lufika na uzagze ni aanhumbe ya kuibahulika. chila munhu yoyose yowoneka kuwakala kuilumba na chilisito chiwona chiya chiyatendile mulungu, wayahudi wowotenda yaja yaligiifana ni iunyinwe tati yetu usang\\'hano ku aaona muladi yamukomfene muhe yochigwi hgumulika, mbali muwe na mweye kwa mwabule uhasanyi. munhu yoyose yogenda mumsanyile ni ptuli wa mtifi na nikukeoni chohokela uko ng\\'hondo,\\' lalilaye muna isi yose,\" lufyaijo kamuuza, \"tegelezinwa zino ifosi. fekise kuulanga kwa mulungu, chila munhu yakalile muna ingava voitosa, haja ija yoyomulongelani mweye mwa wakahi\\'hondi hawmfanyila pmllika. siku isondelele aakiyahima mbaka mbuli zino zano uhuwilo wenu sengo ya mulungu maabaho waukola muladi yadahe kukgmbuka chinogo haulongozi ha mulungu, fana wasang\\'hani wa mndewa wa isika vinogile imwe bule.\" petili viyakal'\n",
      " b'R-hanha na lagono dosili na dizi kulu na kombelosuno na sekemunogele mwihulika mbuli zose za unitondoleni. yesu kamwidika, \"wamuwinza mulungu, mbali kwa uzaha wa mndewa wetafu. lema mbuli mnoge igile ivo hailumuke kulawa mwiisi.\" yesu viyawona kuwagata wanogile wowotegozigwa mabuwa hebu tendeni, simbule mwiko chila munhu yoiwing\\'hile yesu vija ya sika diyelo, nawo wavimanya fana munhu yoyose yomulambiligwe na honhambekyoni sadakwa wenu, ya asiya wakemkwa baianha kwanudaleai a, aoyamandile. mulungu kamulongoza yesu, memaviivo vimuvimanyile vawo chiwona, vino ivo vondaiwe kwa wanhu wa chilisito yesu. iviya niye nokala mgati mmwanza wanahina wake wamsondeleleni yaja yochilondeke kuvumbuka. kwaviya mumundikilani muna ng\\'huli yoinguta na kwinguligwa ulungwana wang\\'wanigwe ugabuligwa chiyalalaliligwe, muludeusoyo nyifa ya kaye ya mulungu watenda lengo mazela. yakalile mulungu, niwatangela, \"lwavikanize mweye kwa mbuli yake kweli.\" lola na kuitena ni ludabwa na kalandula mavala. munhu ija yoya'], shape=(5,), dtype=string) \n",
      "\n",
      "________________________________________________________________________________\n",
      "\n",
      "Run time: 7.364006757736206\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "states = None\n",
    "next_char = tf.constant(['R', 'R', 'R', 'R', 'R'])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(1000):\n",
    "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "  result.append(next_char)\n",
    "\n",
    "result = tf.strings.join(result)\n",
    "end = time.time()\n",
    "print(result, '\\n\\n' + '_'*80)\n",
    "print('\\nRun time:', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "68f10ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.OneStep object at 0x29a610280>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-25 14:57:44.926878: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:absl:Found untraced functions such as gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: one_step/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: one_step/assets\n",
      "2022-10-25 14:57:52.268971: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-10-25 14:57:52.274489: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(one_step_model, 'one_step')\n",
    "one_step_reloaded = tf.saved_model.load('one_step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6e150595",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-25 14:57:52.310306: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-10-25 14:57:52.401095: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-10-25 14:57:52.524702: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-10-25 14:57:52.587841: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chonde cholonda kulonga, sekeyamulolele mulungu yoyowatenda wano wawotambwanw  ndugu zangu.\" saabi moto m\n"
     ]
    }
   ],
   "source": [
    "states = None\n",
    "next_char = tf.constant(['chond'])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(100):\n",
    "  next_char, states = one_step_reloaded.generate_one_step(next_char, states=states)\n",
    "  result.append(next_char)\n",
    "\n",
    "print(tf.strings.join(result)[0].numpy().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181cd1b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
