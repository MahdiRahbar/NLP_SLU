{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49b09d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/student/mrahbar/.local/lib/python3.10/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "[nltk_data] Downloading package punkt to /student/mrahbar/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "2022-12-11 17:50:31.357800: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-11 17:50:31.511789: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-12-11 17:50:31.545131: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-12-11 17:50:34.975271: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /student/mrahbar/cuda/lib64\n",
      "2022-12-11 17:50:34.976369: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /student/mrahbar/cuda/lib64\n",
      "2022-12-11 17:50:34.976388: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import sys \n",
    "import random\n",
    "import time\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from typing import Any, Tuple \n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "import einops \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker \n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import precision_score, recall_score, f1_score \n",
    "from sklearn import preprocessing \n",
    "\n",
    "random.seed(16)\n",
    "\n",
    "import tensorflow as tf \n",
    "import tensorflow_text  as tf_text \n",
    "\n",
    "from Bio import pairwise2\n",
    "from functools import partial\n",
    "from collections import deque\n",
    "import pathlib\n",
    "\n",
    "\n",
    "use_builtins = True\n",
    "\n",
    "import pickle as pkl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39be1f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-11 17:50:40.791491: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-11 17:50:41.651268: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 128 MB memory:  -> device: 0, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:1c:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##########################################################################################\n",
    "# tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "try:\n",
    "    # Disable first GPU\n",
    "    GPUs = tf.config.set_visible_devices(physical_devices[0], 'GPU')\n",
    "#     for gpu in gpus:\n",
    "#         tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_devices = tf.config.list_logical_devices('GPU')\n",
    "\n",
    "except:\n",
    "    # Invalid device or cannot modify virtual devices once initialized.\n",
    "    print(\"Invalid device or cannot modify virtual devices once initialized.\")\n",
    "    pass\n",
    "\n",
    "##########################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ac2c8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train.tsv', 'r') as f: \n",
    "    data = f.read().strip('\\n').split('\\n')\n",
    "    \n",
    "with open('test-03.tsv', 'r') as f: \n",
    "    test_data = f.read().strip('\\n').split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a639ed54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Oradye\\tO-r-a-d-y-e'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6db6dbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data)): \n",
    "    data[i] = data[i].split('\\t')\n",
    "    data[i][0] = list(data[i][0].lower())\n",
    "    data[i][1] = data[i][1].strip('\\n').lower().split('-')\n",
    "    \n",
    "for i in range(len(test_data)): \n",
    "    test_data[i] = test_data[i].split('\\t')\n",
    "    test_data[i][0] = list(test_data[i][0].lower())\n",
    "    test_data[i][1] = test_data[i][1].strip('\\n').lower().split('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1676f6ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['k', 'o', 'n', 's', 'i', 'l', 't', 'a', 'n'],\n",
       " ['k', 'on', 's', 'i', 'l', 't', 'an']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd05bb97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['o', 'r', 'a', 'd', 'y', 'e'], ['o', 'r', 'a', 'd', 'y', 'e']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f1f3aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_pool = [] \n",
    "char_pool = [] \n",
    "for i in range(len(data)):\n",
    "    label_pool += data[i][1]\n",
    "    char_pool += data[i][0]\n",
    "    \n",
    "label_pool = list(set(label_pool))\n",
    "char_pool = list(set(char_pool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fa1048a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'an', 'ch', 'en', 'ng', 'on', 'ou', 'oun', 'ui'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(label_pool).difference(set(char_pool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7c561b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data):\n",
    "    context = [] \n",
    "    target = [] \n",
    "    for i in range(len(data)-1):\n",
    "        temp_context = [] \n",
    "        temp_target = [] \n",
    "        temp_context.append(data[i][0])\n",
    "        temp_target.append(data[i][1])\n",
    "        context += temp_context\n",
    "        target += temp_target\n",
    "\n",
    "    for i in range(len(context)):\n",
    "        context[i] = \" \".join(context[i])\n",
    "        target[i] = \" \".join(target[i])\n",
    "\n",
    "    return target, context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5bcf6202",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_raw, context_raw = load_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62d6e989",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_raw_test, context_raw_test = load_data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ce33840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m a n z è\n",
      "m an z è\n"
     ]
    }
   ],
   "source": [
    "print(context_raw[-1])\n",
    "print(target_raw[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0426a8",
   "metadata": {},
   "source": [
    "## References: \n",
    "### Using an attention-based sequence to sequence encoder decoder\n",
    "1. https://www.tensorflow.org/text/tutorials/nmt_with_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e8896c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShapeChecker():\n",
    "    def __init__(self):\n",
    "        # Keep a cache of every axis-name seen\n",
    "        self.shapes = {}\n",
    "\n",
    "    def __call__(self, tensor, names, broadcast=False):\n",
    "        if not tf.executing_eagerly():\n",
    "            return\n",
    "\n",
    "        parsed = einops.parse_shape(tensor, names)\n",
    "\n",
    "        for name, new_dim in parsed.items():\n",
    "            old_dim = self.shapes.get(name, None)\n",
    "\n",
    "            if (broadcast and new_dim == 1):\n",
    "                continue\n",
    "\n",
    "            if old_dim is None:\n",
    "                # If the axis name is new, add its length to the cache.\n",
    "                self.shapes[name] = new_dim\n",
    "                continue\n",
    "\n",
    "            if new_dim != old_dim:\n",
    "                raise ValueError(f\"Shape mismatch for dimension: '{name}'\\n\"\n",
    "                                 f\"    found: {new_dim}\\n\"\n",
    "                                 f\"    expected: {old_dim}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a8ebb76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-11 17:50:42.448781: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 128.44M (134676480 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n"
     ]
    }
   ],
   "source": [
    "BUFFER_SIZE = len(context_raw)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "is_train = np.random.uniform(size=(len(target_raw),)) < 0.8\n",
    "\n",
    "context_raw_train = []\n",
    "target_raw_train = []  \n",
    "context_raw_val = []\n",
    "target_raw_val = []\n",
    "for i in range(len(is_train)):\n",
    "    if is_train[i]: \n",
    "        context_raw_train.append(context_raw[i])\n",
    "        target_raw_train.append(target_raw[i])\n",
    "    else:\n",
    "        context_raw_val.append(context_raw[i])\n",
    "        target_raw_val.append(target_raw[i])\n",
    "        \n",
    "\n",
    "train_raw = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices((context_raw_train, target_raw_train))\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE))\n",
    "\n",
    "val_raw = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices((context_raw_val, target_raw_val))\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a9b0ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b'f a k i l t e' b'b a g' b'd o m i n k \\xc3\\xa8 n'\n",
      " b's o s y o p o l i t i k' b'r e m i'], shape=(5,), dtype=string)\n",
      "\n",
      "tf.Tensor(\n",
      "[b'f a k i l t e' b'b a g' b'd o m i n k \\xc3\\xa8 n'\n",
      " b's o s y o p o l i t i k' b'r e m i'], shape=(5,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "for example_context_strings, example_target_strings in train_raw.take(1):\n",
    "    print(example_context_strings[:5])\n",
    "    print()\n",
    "    print(example_target_strings[:5])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08c24616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'm a n z \\xc3\\xa8'\n",
      "b'm a n z e\\xcc\\x80'\n"
     ]
    }
   ],
   "source": [
    "example_text = tf.constant('m a n z è')\n",
    "\n",
    "print(example_text.numpy())\n",
    "print(tf_text.normalize_utf8(example_text, 'NFKD').numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ffd09d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_lower_and_split_punct(text):\n",
    "    # Split accented characters.\n",
    "    text = tf_text.normalize_utf8(text, 'NFKD')\n",
    "    text = tf.strings.lower(text)\n",
    "    text = tf.strings.strip(text)\n",
    "\n",
    "    text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "023ee1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m a n z è\n",
      "[START] m a n z è [END]\n"
     ]
    }
   ],
   "source": [
    "print(example_text.numpy().decode())\n",
    "print(tf_lower_and_split_punct(example_text).numpy().decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cadd117d",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vocab_size = 10000\n",
    "\n",
    "context_text_processor = tf.keras.layers.TextVectorization(\n",
    "    standardize=tf_lower_and_split_punct,\n",
    "    max_tokens=max_vocab_size,\n",
    "    ragged=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a0219a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', '[START]', '[END]', 'a', 'n', 'e', 'i', 'o', 's']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_text_processor.adapt(train_raw.map(lambda context, target: context))\n",
    "\n",
    "# Here are the first 10 words from the vocabulary:\n",
    "context_text_processor.get_vocabulary()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "19ffd5b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', '[START]', '[END]', 'a', 'i', 'e', 's', 't', 'l']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_text_processor = tf.keras.layers.TextVectorization(\n",
    "    standardize=tf_lower_and_split_punct,\n",
    "    max_tokens=max_vocab_size,\n",
    "    ragged=True)\n",
    "\n",
    "target_text_processor.adapt(train_raw.map(lambda context, target: target))\n",
    "target_text_processor.get_vocabulary()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5b39e596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[2, 21, 4, 12, 7, 11, 10, 6, 3], [2, 19, 4, 25, 3],\n",
       " [2, 18, 8, 15, 7, 5, 12, 16, 5, 3]]>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_tokens = context_text_processor(example_context_strings)\n",
    "example_tokens[:3, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b07d108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[START] f a k i l t e [END]'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vocab = np.array(context_text_processor.get_vocabulary())\n",
    "tokens = context_vocab[example_tokens[0].numpy()]\n",
    "' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a0061f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(context, target):\n",
    "    context = context_text_processor(context).to_tensor()\n",
    "    target = target_text_processor(target)\n",
    "    targ_in = target[:,:-1].to_tensor()\n",
    "    targ_out = target[:,1:].to_tensor()\n",
    "    return (context, targ_in), targ_out\n",
    "\n",
    "\n",
    "train_ds = train_raw.map(process_text, tf.data.AUTOTUNE)\n",
    "val_ds = val_raw.map(process_text, tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ac6da6d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2  4  5 10 27 10 14  6  3  0]\n",
      "\n",
      "[ 2 15  8 29  8 12  6  0  0  0]\n",
      "[15  8 29  8 12  6  3  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "for (ex_context_tok, ex_tar_in), ex_tar_out in train_ds.take(1):\n",
    "    print(ex_context_tok[0, :10].numpy()) \n",
    "    print()\n",
    "    print(ex_tar_in[0, :10].numpy()) \n",
    "    print(ex_tar_out[0, :10].numpy()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7e63dd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "UNITS = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "85d57c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, text_processor, units):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.text_processor = text_processor\n",
    "        self.vocab_size = text_processor.vocabulary_size()\n",
    "        self.units = units\n",
    "\n",
    "        # The embedding layer converts tokens to vectors\n",
    "        self.embedding = tf.keras.layers.Embedding(self.vocab_size, units,\n",
    "                                                   mask_zero=True)\n",
    "\n",
    "        # The RNN layer processes those vectors sequentially.\n",
    "        self.rnn = tf.keras.layers.Bidirectional(\n",
    "            merge_mode='sum',\n",
    "            layer=tf.keras.layers.GRU(units,\n",
    "                                # Return the sequence and state\n",
    "                                return_sequences=True,\n",
    "                                recurrent_initializer='glorot_uniform'))\n",
    "\n",
    "    def call(self, x):\n",
    "        shape_checker = ShapeChecker()\n",
    "        shape_checker(x, 'batch s')\n",
    "\n",
    "        # 2. The embedding layer looks up the embedding vector for each token.\n",
    "        x = self.embedding(x)\n",
    "        shape_checker(x, 'batch s units')\n",
    "\n",
    "        # 3. The GRU processes the sequence of embeddings.\n",
    "        x = self.rnn(x)\n",
    "        shape_checker(x, 'batch s units')\n",
    "\n",
    "        # 4. Returns the new sequence of embeddings.\n",
    "        return x\n",
    "\n",
    "    def convert_input(self, texts):\n",
    "        texts = tf.convert_to_tensor(texts)\n",
    "        if len(texts.shape) == 0:\n",
    "            texts = tf.convert_to_tensor(texts)[tf.newaxis]\n",
    "        context = self.text_processor(texts).to_tensor()\n",
    "        context = self(context)\n",
    "        return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a3200426",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-11 17:50:44.750686: E tensorflow/stream_executor/cuda/cuda_dnn.cc:389] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\n",
      "2022-12-11 17:50:44.750758: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at cudnn_rnn_ops.cc:1554 : UNKNOWN: Fail to find the dnn implementation.\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Exception encountered when calling layer \"forward_gru\" \"                 f\"(type GRU).\n\n{{function_node __wrapped__CudnnRNNV3_device_/job:localhost/replica:0/task:0/device:GPU:0}} Fail to find the dnn implementation.\n\t [[{{node CudnnRNNV3}}]] [Op:CudnnRNNV3]\n\nCall arguments received by layer \"forward_gru\" \"                 f\"(type GRU):\n  • inputs=tf.Tensor(shape=(32, 14, 32), dtype=float32)\n  • mask=tf.Tensor(shape=(32, 14), dtype=bool)\n  • training=None\n  • initial_state=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Encode the input sequence.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m encoder \u001b[38;5;241m=\u001b[39m Encoder(context_text_processor, UNITS)\n\u001b[0;32m----> 3\u001b[0m ex_context \u001b[38;5;241m=\u001b[39m \u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mex_context_tok\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mContext tokens, shape (batch, s): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mex_context_tok\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEncoder output, shape (batch, s, units): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mex_context\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Input \u001b[0;32mIn [28]\u001b[0m, in \u001b[0;36mEncoder.call\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     26\u001b[0m shape_checker(x, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch s units\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# 3. The GRU processes the sequence of embeddings.\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m shape_checker(x, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch s units\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# 4. Returns the new sequence of embeddings.\u001b[39;00m\n",
      "\u001b[0;31mUnknownError\u001b[0m: Exception encountered when calling layer \"forward_gru\" \"                 f\"(type GRU).\n\n{{function_node __wrapped__CudnnRNNV3_device_/job:localhost/replica:0/task:0/device:GPU:0}} Fail to find the dnn implementation.\n\t [[{{node CudnnRNNV3}}]] [Op:CudnnRNNV3]\n\nCall arguments received by layer \"forward_gru\" \"                 f\"(type GRU):\n  • inputs=tf.Tensor(shape=(32, 14, 32), dtype=float32)\n  • mask=tf.Tensor(shape=(32, 14), dtype=bool)\n  • training=None\n  • initial_state=None"
     ]
    }
   ],
   "source": [
    "# Encode the input sequence.\n",
    "encoder = Encoder(context_text_processor, UNITS)\n",
    "ex_context = encoder(ex_context_tok)\n",
    "\n",
    "print(f'Context tokens, shape (batch, s): {ex_context_tok.shape}')\n",
    "print(f'Encoder output, shape (batch, s, units): {ex_context.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5db8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units, **kwargs):\n",
    "        super().__init__()\n",
    "        self.mha = tf.keras.layers.MultiHeadAttention(key_dim=units, num_heads=1, **kwargs)\n",
    "        self.layernorm = tf.keras.layers.LayerNormalization()\n",
    "        self.add = tf.keras.layers.Add()\n",
    "\n",
    "    def call(self, x, context):\n",
    "        shape_checker = ShapeChecker()\n",
    "\n",
    "        shape_checker(x, 'batch t units')\n",
    "        shape_checker(context, 'batch s units')\n",
    "\n",
    "        attn_output, attn_scores = self.mha(\n",
    "            query=x,\n",
    "            value=context,\n",
    "            return_attention_scores=True)\n",
    "    \n",
    "        shape_checker(x, 'batch t units')\n",
    "        shape_checker(attn_scores, 'batch heads t s')\n",
    "\n",
    "        # Cache the attention scores for plotting later.\n",
    "        attn_scores = tf.reduce_mean(attn_scores, axis=1)\n",
    "        shape_checker(attn_scores, 'batch t s')\n",
    "        self.last_attention_weights = attn_scores\n",
    "\n",
    "        x = self.add([x, attn_output])\n",
    "        x = self.layernorm(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c33b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_layer = CrossAttention(UNITS)\n",
    "\n",
    "# Attend to the encoded tokens\n",
    "embed = tf.keras.layers.Embedding(target_text_processor.vocabulary_size(),\n",
    "                                  output_dim=UNITS, mask_zero=True)\n",
    "ex_tar_embed = embed(ex_tar_in)\n",
    "\n",
    "result = attention_layer(ex_tar_embed, ex_context)\n",
    "\n",
    "print(f'Context sequence, shape (batch, s, units): {ex_context.shape}')\n",
    "print(f'Target sequence, shape (batch, t, units): {ex_tar_embed.shape}')\n",
    "print(f'Attention result, shape (batch, t, units): {result.shape}')\n",
    "print(f'Attention weights, shape (batch, t, s):    {attention_layer.last_attention_weights.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f4d6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_layer.last_attention_weights[0].numpy().sum(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fc7cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_weights = attention_layer.last_attention_weights\n",
    "mask=(ex_context_tok != 0).numpy()\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.pcolormesh(mask*attention_weights[:, 0, :])\n",
    "plt.title('Attention weights')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.pcolormesh(mask)\n",
    "plt.title('Mask');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c646cd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    @classmethod\n",
    "    def add_method(cls, fun):\n",
    "        setattr(cls, fun.__name__, fun)\n",
    "        return fun\n",
    "\n",
    "    def __init__(self, text_processor, units):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.text_processor = text_processor\n",
    "        self.vocab_size = text_processor.vocabulary_size()\n",
    "        self.word_to_id = tf.keras.layers.StringLookup(\n",
    "            vocabulary=text_processor.get_vocabulary(),\n",
    "            mask_token='', oov_token='[UNK]')\n",
    "        self.id_to_word = tf.keras.layers.StringLookup(\n",
    "            vocabulary=text_processor.get_vocabulary(),\n",
    "            mask_token='', oov_token='[UNK]',\n",
    "            invert=True)\n",
    "        self.start_token = self.word_to_id('[START]')\n",
    "        self.end_token = self.word_to_id('[END]')\n",
    "\n",
    "        self.units = units\n",
    "\n",
    "\n",
    "        # 1. The embedding layer converts token IDs to vectors\n",
    "        self.embedding = tf.keras.layers.Embedding(self.vocab_size,\n",
    "                                                   units, mask_zero=True)\n",
    "\n",
    "        # 2. The RNN keeps track of what's been generated so far.\n",
    "        self.rnn = tf.keras.layers.GRU(units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "\n",
    "        # 3. The RNN output will be the query for the attention layer.\n",
    "        self.attention = CrossAttention(units)\n",
    "\n",
    "        # 4. This fully connected layer produces the logits for each\n",
    "        # output token.\n",
    "        self.output_layer = tf.keras.layers.Dense(self.vocab_size)\n",
    "\n",
    "    \n",
    "@Decoder.add_method\n",
    "def call(self,\n",
    "         context, x,\n",
    "         state=None,\n",
    "         return_state=False):  \n",
    "    shape_checker = ShapeChecker()\n",
    "    shape_checker(x, 'batch t')\n",
    "    shape_checker(context, 'batch s units')\n",
    "\n",
    "    # 1. Lookup the embeddings\n",
    "    x = self.embedding(x)\n",
    "    shape_checker(x, 'batch t units')\n",
    "\n",
    "    # 2. Process the target sequence.\n",
    "    x, state = self.rnn(x, initial_state=state)\n",
    "    shape_checker(x, 'batch t units')\n",
    "\n",
    "    # 3. Use the RNN output as the query for the attention over the context.\n",
    "    x = self.attention(x, context)\n",
    "    self.last_attention_weights = self.attention.last_attention_weights\n",
    "    shape_checker(x, 'batch t units')\n",
    "    shape_checker(self.last_attention_weights, 'batch t s')\n",
    "\n",
    "    # Step 4. Generate logit predictions for the next token.\n",
    "    logits = self.output_layer(x)\n",
    "    shape_checker(logits, 'batch t target_vocab_size')\n",
    "\n",
    "    if return_state:\n",
    "        return logits, state\n",
    "    else:\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3da36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Decoder(target_text_processor, UNITS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4c84fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = decoder(ex_context, ex_tar_in)\n",
    "print(f'encoder output shape: (batch, s, units) {ex_context.shape}')\n",
    "print(f'input target tokens shape: (batch, t) {ex_tar_in.shape}')\n",
    "print(f'logits shape shape: (batch, target_vocabulary_size) {logits.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecec4c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "@Decoder.add_method\n",
    "def get_initial_state(self, context):\n",
    "    batch_size = tf.shape(context)[0]\n",
    "    start_tokens = tf.fill([batch_size, 1], self.start_token)\n",
    "    done = tf.zeros([batch_size, 1], dtype=tf.bool)\n",
    "    embedded = self.embedding(start_tokens)\n",
    "    return start_tokens, done, self.rnn.get_initial_state(embedded)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161cb901",
   "metadata": {},
   "outputs": [],
   "source": [
    "@Decoder.add_method\n",
    "def tokens_to_text(self, tokens):\n",
    "    words = self.id_to_word(tokens)\n",
    "    result = tf.strings.reduce_join(words, axis=-1, separator=' ')\n",
    "    result = tf.strings.regex_replace(result, '^ *\\[START\\] *', '')\n",
    "    result = tf.strings.regex_replace(result, ' *\\[END\\] *$', '')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006d792b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@Decoder.add_method\n",
    "def get_next_token(self, context, next_token, done, state, temperature = 0.0):\n",
    "    logits, state = self(\n",
    "    context, next_token,\n",
    "    state = state,\n",
    "    return_state=True) \n",
    "  \n",
    "    if temperature == 0.0:\n",
    "        next_token = tf.argmax(logits, axis=-1)\n",
    "    else:\n",
    "        logits = logits[:, -1, :]/temperature\n",
    "        next_token = tf.random.categorical(logits, num_samples=1)\n",
    "\n",
    "    # If a sequence produces an `end_token`, set it `done`\n",
    "    done = done | (next_token == self.end_token)\n",
    "    # Once a sequence is done it only produces 0-padding.\n",
    "    next_token = tf.where(done, tf.constant(0, dtype=tf.int64), next_token)\n",
    "\n",
    "    return next_token, done, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158f7950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the loop variables.\n",
    "next_token, done, state = decoder.get_initial_state(ex_context)\n",
    "tokens = []\n",
    "\n",
    "for n in range(10):\n",
    "  # Run one step.\n",
    "  next_token, done, state = decoder.get_next_token(\n",
    "      ex_context, next_token, done, state, temperature=1.0)\n",
    "  # Add the token to the output.\n",
    "  tokens.append(next_token)\n",
    "\n",
    "# Stack all the tokens together.\n",
    "tokens = tf.concat(tokens, axis=-1) # (batch, t)\n",
    "\n",
    "# Convert the tokens back to a a string\n",
    "result = decoder.tokens_to_text(tokens)\n",
    "result[:3].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b8417b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Translator(tf.keras.Model):\n",
    "    @classmethod\n",
    "    def add_method(cls, fun):\n",
    "        setattr(cls, fun.__name__, fun)\n",
    "        return fun\n",
    "\n",
    "    def __init__(self, units,\n",
    "                context_text_processor,\n",
    "                target_text_processor):\n",
    "        super().__init__()\n",
    "        # Build the encoder and decoder\n",
    "        encoder = Encoder(context_text_processor, units)\n",
    "        decoder = Decoder(target_text_processor, units)\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def call(self, inputs):\n",
    "        context, x = inputs\n",
    "        context = self.encoder(context)\n",
    "        logits = self.decoder(context, x)\n",
    "\n",
    "        #TODO(b/250038731): remove this\n",
    "        try:\n",
    "            # Delete the keras mask, so keras doesn't scale the loss+accuracy. \n",
    "            del logits._keras_mask\n",
    "        except AttributeError:\n",
    "            pass\n",
    "\n",
    "        return logits\n",
    "    \n",
    "    #@title\n",
    "    # @Translator.add_method\n",
    "    def translate(self,\n",
    "                  texts, *,\n",
    "                  max_length=50,\n",
    "                  temperature=0.0):\n",
    "        # Process the input texts\n",
    "        context = self.encoder.convert_input(texts)\n",
    "        batch_size = tf.shape(texts)[0]\n",
    "\n",
    "        # Setup the loop inputs\n",
    "        tokens = []\n",
    "        attention_weights = []\n",
    "        next_token, done, state = self.decoder.get_initial_state(context)\n",
    "\n",
    "        for _ in range(max_length):\n",
    "            # Generate the next token\n",
    "            next_token, done, state = self.decoder.get_next_token(\n",
    "                context, next_token, done,  state, temperature)\n",
    "\n",
    "            # Collect the generated tokens\n",
    "            tokens.append(next_token)\n",
    "            attention_weights.append(self.decoder.last_attention_weights)\n",
    "\n",
    "            if tf.executing_eagerly() and tf.reduce_all(done):\n",
    "                break\n",
    "\n",
    "        # Stack the lists of tokens and attention weights.\n",
    "        tokens = tf.concat(tokens, axis=-1)   # t*[(batch 1)] -> (batch, t)\n",
    "        self.last_attention_weights = tf.concat(attention_weights, axis=1)  # t*[(batch 1 s)] -> (batch, t s)\n",
    "\n",
    "        result = self.decoder.tokens_to_text(tokens)\n",
    "        return result\n",
    "    \n",
    "    # @Translator.add_method\n",
    "    def plot_attention(self, text, **kwargs):\n",
    "        assert isinstance(text, str)\n",
    "        output = self.translate([text], **kwargs)\n",
    "        output = output[0].numpy().decode()\n",
    "\n",
    "        attention = self.last_attention_weights[0]\n",
    "\n",
    "        context = tf_lower_and_split_punct(text)\n",
    "        context = context.numpy().decode().split()\n",
    "\n",
    "        output = tf_lower_and_split_punct(output)\n",
    "        output = output.numpy().decode().split()[1:]\n",
    "\n",
    "        fig = plt.figure(figsize=(10, 10))\n",
    "        ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "        ax.matshow(attention, cmap='viridis', vmin=0.0)\n",
    "\n",
    "        fontdict = {'fontsize': 14}\n",
    "\n",
    "        ax.set_xticklabels([''] + context, fontdict=fontdict, rotation=90)\n",
    "        ax.set_yticklabels([''] + output, fontdict=fontdict)\n",
    "\n",
    "        ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "        ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "        ax.set_xlabel('Input text')\n",
    "        ax.set_ylabel('Output text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1712a846",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Translator(UNITS, context_text_processor, target_text_processor)\n",
    "\n",
    "logits = model((ex_context_tok, ex_tar_in))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5aeb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_loss(y_true, y_pred):\n",
    "    # Calculate the loss for each item in the batch.\n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True, reduction='none')\n",
    "    loss = loss_fn(y_true, y_pred)\n",
    "\n",
    "    # Mask off the losses on padding.\n",
    "    mask = tf.cast(y_true != 0, loss.dtype)\n",
    "    loss *= mask\n",
    "\n",
    "    # Return the total.\n",
    "    return tf.reduce_sum(loss)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f25493e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_acc(y_true, y_pred):\n",
    "    # Calculate the loss for each item in the batch.\n",
    "    y_pred = tf.argmax(y_pred, axis=-1)\n",
    "    y_pred = tf.cast(y_pred, y_true.dtype)\n",
    "    \n",
    "    match = tf.cast(y_true == y_pred, tf.float32)\n",
    "    mask = tf.cast(y_true != 0, tf.float32)\n",
    "    \n",
    "    return tf.reduce_sum(match)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4081af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=masked_loss, \n",
    "              metrics=[masked_acc, masked_loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2323af",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 1.0 * target_text_processor.vocabulary_size()\n",
    "\n",
    "{\"expected_loss\": tf.math.log(vocab_size).numpy(),\n",
    " \"expected_acc\": 1/vocab_size}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d4b18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5bf88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(val_ds, steps=20, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ef4a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_ds.repeat(), \n",
    "    epochs=15,\n",
    "    steps_per_epoch = 100,\n",
    "    validation_data=val_ds,\n",
    "    validation_steps = 20,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(patience=3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9ad105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_source, test_target = load_data(tagged_list_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90602e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = [] \n",
    "# total = 0\n",
    "# for i in range(len(test_source)):\n",
    "#     result.append(model.translate([test_source[i]])[0].numpy().decode())\n",
    "#     total += nltk.translate.bleu_score.sentence_bleu([test_target[i]], result[-1], weights=[1])\n",
    "# print(total/len(test_source))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848ccd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = [] \n",
    "total = 0\n",
    "for i in range(len(context_raw_test)):\n",
    "    result.append(model.translate([context_raw_test[i]])[0].numpy().decode())\n",
    "    total += nltk.translate.bleu_score.sentence_bleu([target_raw_test[i]], result[-1], weights=[1])\n",
    "print(total/len(context_raw_test))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c35688",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot_attention(context_raw_test[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f94726",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(context_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fce6af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_raw[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf02008",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5812657d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.translate([text], **kwargs)\n",
    "output = output[0].numpy().decode()\n",
    "\n",
    "attention = self.last_attention_weights[0]\n",
    "\n",
    "context = tf_lower_and_split_punct(text)\n",
    "context = context.numpy().decode().split()\n",
    "\n",
    "output = tf_lower_and_split_punct(output)\n",
    "output = output.numpy().decode().split()[1:]\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "ax.matshow(attention, cmap='viridis', vmin=0.0)\n",
    "\n",
    "fontdict = {'fontsize': 14}\n",
    "\n",
    "ax.set_xticklabels([''] + context, fontdict=fontdict, rotation=90)\n",
    "ax.set_yticklabels([''] + output, fontdict=fontdict)\n",
    "\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "ax.set_xlabel('Input text')\n",
    "ax.set_ylabel('Output text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253817b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.rand(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a74439",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fce9111",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87d62e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
